{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n\n#!pip install numpy==1.17.5\n#!pip install -U numpy==1.11.0\n!pip3 install numpy==1.17.4\n\nimport numpy as np\nimport pandas as pd \nfrom tqdm import tqdm\n\nfrom matplotlib import image\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nimport cv2\n\n!pip install fastai --upgrade\n\nimport torch \nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms\n\nfrom fastai.vision.all import *","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-21T05:11:55.401402Z","iopub.execute_input":"2021-10-21T05:11:55.402256Z","iopub.status.idle":"2021-10-21T05:12:19.322201Z","shell.execute_reply.started":"2021-10-21T05:11:55.402157Z","shell.execute_reply":"2021-10-21T05:12:19.321338Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"coord_df = pd.read_csv('../input/car-object-detection/data/train_solution_bounding_boxes (1).csv')\ncoord_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T05:12:19.324065Z","iopub.execute_input":"2021-10-21T05:12:19.324384Z","iopub.status.idle":"2021-10-21T05:12:19.360299Z","shell.execute_reply.started":"2021-10-21T05:12:19.324347Z","shell.execute_reply":"2021-10-21T05:12:19.359467Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"plt_image = image.imread('../input/car-object-detection/data/training_images/vid_4_10480.jpg')\n\nprint(plt_image.dtype)\nprint(plt_image.shape)\n\nfig, ax = plt.subplots()\n\nax.imshow(plt_image)\n\nxmin = float(coord_df[coord_df[\"image\"] == \"vid_4_10480.jpg\"]['xmin'])\nymin = float(coord_df[coord_df[\"image\"] == \"vid_4_10480.jpg\"]['ymin'])\nxmax = float(coord_df[coord_df[\"image\"] == \"vid_4_10480.jpg\"]['xmax'])\nymax = float(coord_df[coord_df[\"image\"] == \"vid_4_10480.jpg\"]['ymax'])\n\nprint(xmin, ymin, xmax, ymax)\n\nrect = patches.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, linewidth=1, edgecolor='r', facecolor='none')\n\nax.add_patch(rect)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-21T05:12:19.361911Z","iopub.execute_input":"2021-10-21T05:12:19.362455Z","iopub.status.idle":"2021-10-21T05:12:19.696016Z","shell.execute_reply.started":"2021-10-21T05:12:19.362413Z","shell.execute_reply":"2021-10-21T05:12:19.695247Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"bbox_cols = ['xmin', 'ymin', 'xmax', 'ymax']\n\ndef get_target_ds(file_name, df): \n    rows = df[df[\"image\"] == file_name[51:]]  \n    bbox = []\n    for row in rows[bbox_cols].values:\n        bbox_entry = []\n        for box in row:\n            bbox_entry.append(box)\n        bbox.append(bbox_entry)\n    return bbox\n\nclass CarDetectionDataset(torch.utils.data.Dataset):  \n    def __init__(self, images_path, df, std=False):\n        super(CarDetectionDataset, self).__init__()\n        self.images_path = glob.glob(images_path+\"*\")\n        self.df = df\n        self.std = std\n        self.bbox_cols = ['xmin', 'ymin', 'xmax', 'ymax']\n        \n    def __len__(self):\n        return len(self.images_path)  \n\n    def __getitem__(self, idx):\n        file_path = self.images_path[idx]\n        rows = self.df[self.df[\"image\"] == file_path[51:]]\n        bbox = rows[self.bbox_cols].values\n        \n        img = cv2.imread(str(file_path), cv2.IMREAD_UNCHANGED)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n        \n        #boxes = get_target_ds(img_path, self.df)\n        boxes = np.array(bbox)\n        bbox[:, 2] = bbox[:, 0] + bbox[:, 2]\n        bbox[:, 3] = bbox[:, 1] + bbox[:, 3]\n        \n        areas = (bbox[:, 3] - bbox[:, 1]) * (bbox[:, 2] - bbox[:, 0])\n        bbox = torch.from_numpy(bbox) \n        bbox = torch.as_tensor(bbox, dtype=torch.int64)\n        \n        if self.std:\n            img = img/255.0\n            \n        img = img.reshape(3, img.shape[0], img.shape[1])\n        target = {}\n        \n        labels = torch.ones((bbox.shape[0]), dtype=torch.int64)            \n        \n        image_id = torch.tensor([idx])\n        \n        areas = torch.as_tensor(areas.astype(np.float), dtype=torch.double)\n        iscrowd = torch.zeros((boxes.shape[0],))\n        \n        target[\"boxes\"] = bbox\n        target[\"labels\"] = labels\n        target[\"area\"] = areas\n        target[\"iscrowd\"] = iscrowd\n        target[\"image_id\"] = image_id    \n        img = torch.from_numpy(img)\n        img = torch.as_tensor(img, dtype=torch.double)\n        \n        return img, target","metadata":{"execution":{"iopub.status.busy":"2021-10-21T05:12:19.697853Z","iopub.execute_input":"2021-10-21T05:12:19.698111Z","iopub.status.idle":"2021-10-21T05:12:19.714616Z","shell.execute_reply.started":"2021-10-21T05:12:19.698076Z","shell.execute_reply":"2021-10-21T05:12:19.713032Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dataset = CarDetectionDataset(\"../input/car-object-detection/data/training_images/\", coord_df)\nimg, target = dataset.__getitem__(300)\nimg = img.reshape(img.shape[1], img.shape[2], 3)\nimg = torch.as_tensor(img, dtype=torch.int)\nprint(img.shape, target[\"boxes\"], target[\"labels\"])\n\nfig, ax = plt.subplots(figsize=(20,20))\nax.imshow(img)\nrect = patches.Rectangle((125, 187), 391-125, 423-187, linewidth=1, edgecolor='r', facecolor='none')\nax.add_patch(rect)\nrect = patches.Rectangle((614, 178), 1290-614, 410-178, linewidth=1, edgecolor='r', facecolor='none')\nax.add_patch(rect)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-21T05:12:19.715674Z","iopub.execute_input":"2021-10-21T05:12:19.716347Z","iopub.status.idle":"2021-10-21T05:12:20.686506Z","shell.execute_reply.started":"2021-10-21T05:12:19.716308Z","shell.execute_reply":"2021-10-21T05:12:20.685662Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    return tuple(zip(*batch))\n\ndataset = CarDetectionDataset(\"../input/car-object-detection/data/training_images/\", coord_df, std=True)\n\n# split the dataset in train and test set\nindices = torch.randperm(len(dataset)).tolist()\ntrain_dataset = torch.utils.data.Subset(dataset, indices[:-300])\nval_dataset = torch.utils.data.Subset(dataset, indices[-300:])\n\n# define training and validation data loaders\ntrain_dataloader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=4, shuffle=True, num_workers=0,\n        collate_fn = collate_fn)\n\nval_dataloader = torch.utils.data.DataLoader(\n        val_dataset, batch_size=1, shuffle=False, num_workers=0,\n        collate_fn = collate_fn)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T05:12:20.688084Z","iopub.execute_input":"2021-10-21T05:12:20.688578Z","iopub.status.idle":"2021-10-21T05:12:20.715827Z","shell.execute_reply.started":"2021-10-21T05:12:20.688538Z","shell.execute_reply":"2021-10-21T05:12:20.714801Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"if(torch.cuda.is_available()):\n    device = torch.device(\"cuda\")\n    print(\"Device:\", device, torch.cuda.get_device_name(0))\nelse:\n    device= torch.device(\"cpu\")\n    print(\"Device:\", device)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T05:12:20.718199Z","iopub.execute_input":"2021-10-21T05:12:20.718913Z","iopub.status.idle":"2021-10-21T05:12:20.735897Z","shell.execute_reply.started":"2021-10-21T05:12:20.718873Z","shell.execute_reply":"2021-10-21T05:12:20.734551Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"%%sh\nif [ ! -d \"output/vision\" ]; then\n    git clone https://github.com/pytorch/vision.git output/vision\nelse\n    echo \"output/vision already cloned\"\nfi\n\ncp output/vision/references/detection/utils.py .\ncp output/vision/references/detection/transforms.py .\ncp output/vision/references/detection/coco_eval.py .\ncp output/vision/references/detection/engine.py .\ncp output/vision/references/detection/coco_utils.py .","metadata":{"execution":{"iopub.status.busy":"2021-10-21T05:12:20.737510Z","iopub.execute_input":"2021-10-21T05:12:20.737774Z","iopub.status.idle":"2021-10-21T05:12:30.969648Z","shell.execute_reply.started":"2021-10-21T05:12:20.737740Z","shell.execute_reply":"2021-10-21T05:12:30.968873Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip3 install pycocotools\n!pip3 install -U scikit-image\n!pip3 install -U cython ","metadata":{"execution":{"iopub.status.busy":"2021-10-21T05:12:30.972025Z","iopub.execute_input":"2021-10-21T05:12:30.972305Z","iopub.status.idle":"2021-10-21T05:13:01.528333Z","shell.execute_reply.started":"2021-10-21T05:12:30.972268Z","shell.execute_reply":"2021-10-21T05:13:01.527412Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n\nfasterRCNN_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\nin_features = fasterRCNN_model.roi_heads.box_predictor.cls_score.in_features\nfasterRCNN_model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T05:54:01.461348Z","iopub.execute_input":"2021-10-21T05:54:01.462124Z","iopub.status.idle":"2021-10-21T05:54:02.074008Z","shell.execute_reply.started":"2021-10-21T05:54:01.462084Z","shell.execute_reply":"2021-10-21T05:54:02.073249Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class LossAverager:\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2021-10-21T05:51:19.031743Z","iopub.execute_input":"2021-10-21T05:51:19.032002Z","iopub.status.idle":"2021-10-21T05:51:19.037730Z","shell.execute_reply.started":"2021-10-21T05:51:19.031973Z","shell.execute_reply":"2021-10-21T05:51:19.036961Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from engine import train_one_epoch, evaluate\nimport time\n\ntrain_loss_hist = LossAverager()\nval_loss_hist = LossAverager()\nEPOCHS = 10\n\nfasterRCNN_model.double()\nfasterRCNN_model.to(device)\n\nparams = [p for p in fasterRCNN_model.parameters() if p.requires_grad]\noptimizer = torch.optim.Adam(params, lr=0.0005)#, momentum=0.9, weight_decay=0.0005)\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n                                                   step_size=3,\n                                                   gamma=0.1)\n\n\nfor epoch in range(EPOCHS):\n    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n    start_time = time.time()\n    fasterRCNN_model.train()\n    train_loss_hist.reset()\n    \n    for images, targets in tqdm(train_dataloader):\n        \n        images = torch.stack(images).to(device)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n        \n        bs = images.shape[0]\n        \n        loss_dict = fasterRCNN_model(images, targets)\n        \n        totalLoss = sum(loss for loss in loss_dict.values())\n        lossValue = totalLoss.item()\n        \n        train_loss_hist.update(lossValue,bs)\n\n        optimizer.zero_grad()\n        totalLoss.backward()\n        optimizer.step()\n        lr_scheduler.step(totalLoss)\n        \n    print(f\"Train loss: {train_loss_hist.avg}\")\n    !rm -rf ./output/\n    evaluate(fasterRCNN_model, val_dataloader, device=device)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T05:55:00.837087Z","iopub.execute_input":"2021-10-21T05:55:00.837371Z","iopub.status.idle":"2021-10-21T06:54:01.696762Z","shell.execute_reply.started":"2021-10-21T05:55:00.837339Z","shell.execute_reply":"2021-10-21T06:54:01.695366Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"fasterRCNN_model.eval()\n!rm -rf ./output/\nevaluate(fasterRCNN_model, val_dataloader, device=device)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T06:54:21.159330Z","iopub.execute_input":"2021-10-21T06:54:21.159623Z","iopub.status.idle":"2021-10-21T06:55:39.034365Z","shell.execute_reply.started":"2021-10-21T06:54:21.159591Z","shell.execute_reply":"2021-10-21T06:55:39.033621Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"images = cv2.imread(\"../input/car-object-detection/data/testing_images/vid_5_26640.jpg\", cv2.IMREAD_COLOR)\nimages = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\nimages = torch.as_tensor(images.astype(np.float), dtype=torch.double)\nimages /= 255.0\n\ncpu_device = torch.device(\"cpu\")\n\nsample = images\nimages = torch.tensor(images)\nimages = images.permute(2,0,1)\nimages = torch.unsqueeze(images, 0)\nimages = images.to(cpu_device)\nfasterRCNN_model.eval()\n\nfasterRCNN_model.to(cpu_device)\noutputs = fasterRCNN_model(images)\noutputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\nboxes = outputs[0][\"boxes\"].detach().numpy().astype(np.int32)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T06:59:17.209758Z","iopub.execute_input":"2021-10-21T06:59:17.210084Z","iopub.status.idle":"2021-10-21T06:59:33.002172Z","shell.execute_reply.started":"2021-10-21T06:59:17.210052Z","shell.execute_reply":"2021-10-21T06:59:33.001450Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,20))\nax.imshow(sample)\nfor box in boxes:\n    rect = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], linewidth=1, edgecolor='r', facecolor='none')\n    ax.add_patch(rect)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-21T07:03:27.339700Z","iopub.execute_input":"2021-10-21T07:03:27.340328Z","iopub.status.idle":"2021-10-21T07:03:28.113729Z","shell.execute_reply.started":"2021-10-21T07:03:27.340288Z","shell.execute_reply":"2021-10-21T07:03:28.113101Z"},"trusted":true},"execution_count":28,"outputs":[]}]}